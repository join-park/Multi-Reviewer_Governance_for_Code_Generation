# ê¸°ë³¸ ì„¤ì •
import os
from langchain_ollama import ChatOllama, OllamaEmbeddings

# Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ ì„œë²„ URL
BASE_URL = "http://localhost:11434"

# ğŸ’¡ ëª¨ë¸ ì„ íƒ
# - llama3.1: ì¼ë°˜ì ì¸ ëŒ€í™”ì™€ ì¶”ë¡ ì„ ì˜í•¨ (ë¬¸ê³¼ìƒ ëŠë‚Œ)
# - qwen2.5-coder: ì½”ë”©ì„ ê¸°ê°€ ë§‰íˆê²Œ ì˜í•¨ (ì´ê³¼ìƒ ëŠë‚Œ)
LLM_NAME = "llama3.1:8b"
CODE_LLM_NAME = "qwen2.5-coder:7b"

# LangChain LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = ChatOllama(
    model=LLM_NAME,
    temperature=0,
    base_url=BASE_URL
)

code_llm = ChatOllama(
    model=CODE_LLM_NAME,
    temperature=0.1,
    base_url=BASE_URL
)

embedding = OllamaEmbeddings(model="nomic-embed-text", base_url=BASE_URL)

print(f"ì¤€ë¹„ ì™„ë£Œ! ëŒ€í™”ìš© ëª¨ë¸: {LLM_NAME}, ì½”ë”©ìš© ëª¨ë¸: {CODE_LLM_NAME}")